{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCL Detection — Binary Classification Pipeline\n",
    "\n",
    "Systematic approach to PCL binary classification:\n",
    "1. True baseline (RoBERTa-base, unweighted CE, t=0.5)\n",
    "2. Incremental improvements: weighted CE, threshold optimisation, multi-task learning\n",
    "3. Ablation studies showing contribution of each component\n",
    "4. Error analysis and custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Running on GPU — batch_size=4, grad_accum=8\n",
      "Effective batch size: 32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "# Auto-detect environment and set batch sizes accordingly\n",
    "ON_GPUDOJO = 'COLAB_GPU' in os.environ or 'COLAB_RELEASE_TAG' in os.environ or DEVICE.type == 'cuda'\n",
    "\n",
    "if ON_GPUDOJO:\n",
    "    BASE_DIR = '/vol/bitbucket/akc123/PCL_Detection'\n",
    "    BATCH_SIZE = 4\n",
    "    GRAD_ACCUM = 8\n",
    "    EVAL_BATCH_SIZE = 16\n",
    "    print('Running on GPU — batch_size=4, grad_accum=8')\n",
    "else:\n",
    "    BASE_DIR = '/Users/alexanderchow/Documents/Y3/60035_NLP/PCL_Detection'\n",
    "    BATCH_SIZE = 2\n",
    "    GRAD_ACCUM = 16\n",
    "    EVAL_BATCH_SIZE = 4\n",
    "    print('Running locally (MPS/CPU) — batch_size=2, grad_accum=16')\n",
    "\n",
    "print(f'Effective batch size: {BATCH_SIZE * GRAD_ACCUM}')\n",
    "\n",
    "DATA_DIR = f'{BASE_DIR}/data'\n",
    "SPLITS_DIR = f'{BASE_DIR}/practice splits'\n",
    "CHECKPOINT_DIR = f'{BASE_DIR}/checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8375 samples (794 PCL)\n",
      "Dev:   2094 samples (199 PCL)\n",
      "\n",
      "Train class distribution:\n",
      "binary_label\n",
      "0    7581\n",
      "1     794\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load main PCL dataset (skip 4 header lines)\n",
    "pcl_df = pd.read_csv(\n",
    "    f'{DATA_DIR}/dontpatronizeme_pcl.tsv',\n",
    "    sep='\\t', skiprows=4, header=None,\n",
    "    names=['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label'],\n",
    "    quoting=3\n",
    ")\n",
    "pcl_df['par_id'] = pcl_df['par_id'].astype(int)\n",
    "pcl_df['label'] = pcl_df['label'].astype(int)\n",
    "\n",
    "# Binary label: {0,1}->0, {2,3,4}->1\n",
    "pcl_df['binary_label'] = (pcl_df['label'] >= 2).astype(int)\n",
    "\n",
    "# Clean text: strip <h> tags and HTML artifacts\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)       # remove HTML tags\n",
    "    text = re.sub(r'&[a-z]+;', ' ', text)      # remove HTML entities\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    # normalise whitespace\n",
    "    return text\n",
    "pcl_df['text'] = pcl_df['text'].apply(clean_text)\n",
    "\n",
    "# Load train/dev splits\n",
    "train_splits = pd.read_csv(f'{SPLITS_DIR}/train_semeval_parids-labels.csv')\n",
    "dev_splits = pd.read_csv(f'{SPLITS_DIR}/dev_semeval_parids-labels.csv')\n",
    "train_splits['par_id'] = train_splits['par_id'].astype(int)\n",
    "dev_splits['par_id'] = dev_splits['par_id'].astype(int)\n",
    "\n",
    "# Parse category labels from split files (7-dim multi-label vectors)\n",
    "def parse_category_label(label_str):\n",
    "    try:\n",
    "        return ast.literal_eval(label_str)\n",
    "    except:\n",
    "        return [0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "train_splits['category_labels'] = train_splits['label'].apply(parse_category_label)\n",
    "dev_splits['category_labels'] = dev_splits['label'].apply(parse_category_label)\n",
    "\n",
    "# Merge with main data\n",
    "train_ids = set(train_splits['par_id'].values)\n",
    "dev_ids = set(dev_splits['par_id'].values)\n",
    "\n",
    "train_df = pcl_df[pcl_df['par_id'].isin(train_ids)].copy()\n",
    "dev_df = pcl_df[pcl_df['par_id'].isin(dev_ids)].copy()\n",
    "\n",
    "# Merge category labels\n",
    "cat_train = train_splits[['par_id', 'category_labels']].copy()\n",
    "cat_dev = dev_splits[['par_id', 'category_labels']].copy()\n",
    "\n",
    "train_df = train_df.merge(cat_train, on='par_id', how='left')\n",
    "dev_df = dev_df.merge(cat_dev, on='par_id', how='left')\n",
    "\n",
    "# Fill missing category labels with zeros\n",
    "train_df['category_labels'] = train_df['category_labels'].apply(\n",
    "    lambda x: x if isinstance(x, list) else [0]*7\n",
    ")\n",
    "dev_df['category_labels'] = dev_df['category_labels'].apply(\n",
    "    lambda x: x if isinstance(x, list) else [0]*7\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_df)} samples ({train_df[\"binary_label\"].sum()} PCL)')\n",
    "print(f'Dev:   {len(dev_df)} samples ({dev_df[\"binary_label\"].sum()} PCL)')\n",
    "print(f'\\nTrain class distribution:')\n",
    "print(train_df['binary_label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: roberta-base\n",
      "Max length: 256\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'roberta-base'\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class PCLDataset(Dataset):\n",
    "    def __init__(self, texts, binary_labels, category_labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.binary_labels = binary_labels\n",
    "        self.category_labels = category_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'binary_label': torch.tensor(self.binary_labels[idx], dtype=torch.long),\n",
    "            'category_labels': torch.tensor(self.category_labels[idx], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "def create_datasets(train_df, dev_df, tokenizer, max_length):\n",
    "    train_dataset = PCLDataset(\n",
    "        texts=train_df['text'].tolist(),\n",
    "        binary_labels=train_df['binary_label'].tolist(),\n",
    "        category_labels=train_df['category_labels'].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    dev_dataset = PCLDataset(\n",
    "        texts=dev_df['text'].tolist(),\n",
    "        binary_labels=dev_df['binary_label'].tolist(),\n",
    "        category_labels=dev_df['category_labels'].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    return train_dataset, dev_dataset\n",
    "\n",
    "print(f'Tokenizer loaded: {MODEL_NAME}')\n",
    "print(f'Max length: {MAX_LENGTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes defined: PCLMultiTaskModel, BaselineModel\n"
     ]
    }
   ],
   "source": [
    "class PCLMultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_categories=7, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "\n",
    "        self.binary_head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 2)\n",
    "        )\n",
    "\n",
    "        self.category_head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_categories)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        binary_logits = self.binary_head(cls_output)\n",
    "        category_logits = self.category_head(cls_output)\n",
    "\n",
    "        return binary_logits, category_logits\n",
    "\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    \"\"\"Simple RoBERTa-base binary classifier (baseline).\"\"\"\n",
    "    def __init__(self, model_name='roberta-base', dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits, None  # None for compatibility with evaluate()\n",
    "\n",
    "print('Model classes defined: PCLMultiTaskModel, BaselineModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print_every_updates = 20\n",
    "\n",
    "def free_gpu():\n",
    "    \"\"\"Clear GPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def evaluate(model, dataloader, device, threshold=0.5):\n",
    "    \"\"\"Evaluate model on a dataset, return metrics and probabilities.\"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['binary_label']\n",
    "\n",
    "            binary_logits, _ = model(input_ids, attention_mask)\n",
    "            probs = F.softmax(binary_logits, dim=1)[:, 1].cpu()\n",
    "\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "\n",
    "    all_preds = [1 if p >= threshold else 0 for p in all_probs]\n",
    "    f1 = f1_score(all_labels, all_preds, pos_label=1)\n",
    "    precision = precision_score(all_labels, all_preds, pos_label=1, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, pos_label=1, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'f1': f1, 'precision': precision, 'recall': recall,\n",
    "        'preds': all_preds, 'labels': all_labels, 'probs': all_probs,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "\n",
    "def find_best_threshold(probs, labels):\n",
    "    \"\"\"Sweep thresholds on probability outputs to maximise F1.\"\"\"\n",
    "    best_f1 = 0.0\n",
    "    best_threshold = 0.5\n",
    "    for t in np.arange(0.05, 0.95, 0.01):\n",
    "        preds = [1 if p >= t else 0 for p in probs]\n",
    "        f1 = f1_score(labels, preds, pos_label=1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = t\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "\n",
    "def train_model(config_name, train_df, dev_df, tokenizer,\n",
    "                use_weighted_ce=True, use_threshold_opt=True, use_multitask=False,\n",
    "                num_epochs=10, batch_size=BATCH_SIZE, grad_accum_steps=GRAD_ACCUM,\n",
    "                lr=2e-5, weight_decay=0.01, patience=3, category_weight=0.3,\n",
    "                model_class=PCLMultiTaskModel, model_name='roberta-base'):\n",
    "    \"\"\"Train a model with the given configuration.\"\"\"\n",
    "    free_gpu()\n",
    "\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Training Config: {config_name}')\n",
    "    print(f'  Model: {model_name}')\n",
    "    print(f'  Weighted CE: {use_weighted_ce} | Multi-task: {use_multitask}')\n",
    "    print(f'  Threshold Opt: {use_threshold_opt}')\n",
    "    print(f'  Epochs: {num_epochs} | LR: {lr} | Patience: {patience}')\n",
    "    print(f'  Batch: {batch_size} x {grad_accum_steps} = {batch_size * grad_accum_steps} effective')\n",
    "    print(f'{\"=\"*60}')\n",
    "\n",
    "    effective_train_df = train_df.copy()\n",
    "\n",
    "    # Create tokenizer for this model\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_dataset = PCLDataset(\n",
    "        texts=effective_train_df['text'].tolist(),\n",
    "        binary_labels=effective_train_df['binary_label'].tolist(),\n",
    "        category_labels=effective_train_df['category_labels'].tolist(),\n",
    "        tokenizer=tok, max_length=MAX_LENGTH\n",
    "    )\n",
    "    dev_dataset = PCLDataset(\n",
    "        texts=dev_df['text'].tolist(),\n",
    "        binary_labels=dev_df['binary_label'].tolist(),\n",
    "        category_labels=dev_df['category_labels'].tolist(),\n",
    "        tokenizer=tok, max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Model\n",
    "    if model_class == BaselineModel:\n",
    "        model = BaselineModel(model_name=model_name).to(DEVICE).float()\n",
    "    else:\n",
    "        model = PCLMultiTaskModel(model_name=model_name).to(DEVICE).float()\n",
    "\n",
    "    # Loss function\n",
    "    if use_weighted_ce:\n",
    "        n_neg = (effective_train_df['binary_label'] == 0).sum()\n",
    "        n_pos = (effective_train_df['binary_label'] == 1).sum()\n",
    "        weight = torch.tensor([1.0, n_neg / n_pos], dtype=torch.float).to(DEVICE)\n",
    "        binary_criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "        print(f'  CE class weights: [{weight[0]:.3f}, {weight[1]:.3f}]')\n",
    "    else:\n",
    "        binary_criterion = nn.CrossEntropyLoss()\n",
    "        print(f'  Unweighted CE')\n",
    "\n",
    "    category_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Optimizer & scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * num_epochs // grad_accum_steps\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            binary_labels = batch['binary_label'].to(DEVICE)\n",
    "            category_labels = batch['category_labels'].to(DEVICE)\n",
    "\n",
    "            binary_logits, category_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            loss_binary = binary_criterion(binary_logits, binary_labels)\n",
    "            if use_multitask and category_logits is not None:\n",
    "                loss_category = category_criterion(category_logits, category_labels)\n",
    "                loss = loss_binary + category_weight * loss_category\n",
    "            else:\n",
    "                loss = loss_binary\n",
    "            loss = loss / grad_accum_steps\n",
    "\n",
    "            loss.backward()\n",
    "            total_loss += loss.item() * grad_accum_steps\n",
    "\n",
    "            if (step + 1) % grad_accum_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                update = (step + 1) // grad_accum_steps\n",
    "                if update % print_every_updates == 0:\n",
    "                    avg_recent = total_loss / (step + 1)\n",
    "                    print(f\"    step {step+1}/{len(train_loader)} \"\n",
    "                          f\"(update {update}) | avg loss so far: {avg_recent:.4f}\")\n",
    "\n",
    "        # Handle remaining gradients\n",
    "        if (step + 1) % grad_accum_steps != 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Evaluate on dev at t=0.5\n",
    "        metrics = evaluate(model, dev_loader, DEVICE, threshold=0.5)\n",
    "        history.append({\n",
    "            'epoch': epoch + 1, 'loss': avg_loss,\n",
    "            'f1': metrics['f1'], 'precision': metrics['precision'], 'recall': metrics['recall']\n",
    "        })\n",
    "\n",
    "        print(f'  Epoch {epoch+1}/{num_epochs} — Loss: {avg_loss:.4f} | '\n",
    "              f'F1: {metrics[\"f1\"]:.4f} | P: {metrics[\"precision\"]:.4f} | R: {metrics[\"recall\"]:.4f}')\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f'{CHECKPOINT_DIR}/{config_name}_best.pt')\n",
    "            print(f'  -> New best F1! Saved.')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'  Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/{config_name}_best.pt', weights_only=True))\n",
    "\n",
    "    # Evaluate at t=0.5\n",
    "    final_metrics = evaluate(model, dev_loader, DEVICE, threshold=0.5)\n",
    "\n",
    "    # Threshold optimisation (if enabled)\n",
    "    if use_threshold_opt:\n",
    "        best_thresh, _ = find_best_threshold(final_metrics['probs'], final_metrics['labels'])\n",
    "        thresh_metrics = evaluate(model, dev_loader, DEVICE, threshold=best_thresh)\n",
    "    else:\n",
    "        best_thresh = 0.5\n",
    "        thresh_metrics = final_metrics\n",
    "\n",
    "    print(f'\\n  Dev F1 @ t=0.50: {final_metrics[\"f1\"]:.4f}')\n",
    "    if use_threshold_opt:\n",
    "        print(f'  Dev F1 @ t={best_thresh:.2f} (optimised): {thresh_metrics[\"f1\"]:.4f}')\n",
    "    print(classification_report(\n",
    "        thresh_metrics['labels'], thresh_metrics['preds'],\n",
    "        target_names=['No PCL', 'PCL'], digits=4\n",
    "    ))\n",
    "\n",
    "    # Move to CPU and free GPU\n",
    "    model = model.cpu()\n",
    "    del model; free_gpu()\n",
    "\n",
    "    return final_metrics, thresh_metrics, history, best_thresh, tok\n",
    "\n",
    "print('Training function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. True Baseline: RoBERTa-base + Unweighted CE + t=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Config: baseline\n",
      "  Model: roberta-base\n",
      "  Weighted CE: False | Multi-task: False\n",
      "  Threshold Opt: False\n",
      "  Epochs: 10 | LR: 2e-05 | Patience: 3\n",
      "  Batch: 4 x 8 = 32 effective\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 1210.95it/s, Materializing param=encoder.layer.11.output.dense.weight]             \n",
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unweighted CE\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.4950\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.4700\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.4190\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.3954\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.3883\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.3798\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.3610\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.3464\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.3346\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.3270\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.3179\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.3078\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.3029\n",
      "  Epoch 1/10 — Loss: 0.3028 | F1: 0.4800 | P: 0.6190 | R: 0.3920\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.2345\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.2255\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.2165\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.2106\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.2030\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.2014\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.1991\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.1939\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.1998\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.2018\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.2003\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.1998\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.2000\n",
      "  Epoch 2/10 — Loss: 0.2004 | F1: 0.5449 | P: 0.6178 | R: 0.4874\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.1399\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.1568\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.1410\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.1399\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.1375\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.1367\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.1352\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.1282\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.1307\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.1315\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.1337\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.1331\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.1326\n",
      "  Epoch 3/10 — Loss: 0.1325 | F1: 0.5367 | P: 0.7368 | R: 0.4221\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0649\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0607\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0587\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0657\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0694\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0667\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0736\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0764\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0766\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0775\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0769\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0771\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0777\n",
      "  Epoch 4/10 — Loss: 0.0781 | F1: 0.5731 | P: 0.6853 | R: 0.4925\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0409\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0317\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0340\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0416\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0398\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0381\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0364\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0380\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0379\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0374\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0358\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0367\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0355\n",
      "  Epoch 5/10 — Loss: 0.0354 | F1: 0.5892 | P: 0.6753 | R: 0.5226\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0401\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0306\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0264\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0252\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0238\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0234\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0213\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0193\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0206\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0203\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0189\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0182\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0182\n",
      "  Epoch 6/10 — Loss: 0.0181 | F1: 0.6243 | P: 0.6933 | R: 0.5678\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0104\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0085\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0110\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0121\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0122\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0111\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0113\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0109\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0109\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0101\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0098\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0101\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0105\n",
      "  Epoch 7/10 — Loss: 0.0104 | F1: 0.5759 | P: 0.7500 | R: 0.4673\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0056\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0032\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0033\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0035\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0028\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0025\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0022\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0022\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0023\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0027\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0028\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0033\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0031\n",
      "  Epoch 8/10 — Loss: 0.0031 | F1: 0.5723 | P: 0.7143 | R: 0.4774\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0011\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0006\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0007\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0013\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0014\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0016\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0014\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0013\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0016\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0025\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0031\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0036\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0034\n",
      "  Epoch 9/10 — Loss: 0.0035 | F1: 0.5971 | P: 0.7055 | R: 0.5176\n",
      "  Early stopping at epoch 9\n",
      "\n",
      "  Dev F1 @ t=0.50: 0.6243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      No PCL     0.9555    0.9736    0.9645      1895\n",
      "         PCL     0.6933    0.5678    0.6243       199\n",
      "\n",
      "    accuracy                         0.9351      2094\n",
      "   macro avg     0.8244    0.7707    0.7944      2094\n",
      "weighted avg     0.9305    0.9351    0.9321      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# True baseline: RoBERTa-base, unweighted CE, no tricks, fixed threshold=0.5\n",
    "BASELINE_MODEL = 'roberta-base'\n",
    "\n",
    "metrics_bl, thresh_metrics_bl, history_bl, thresh_bl, tok_bl = train_model(\n",
    "    config_name='baseline',\n",
    "    train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n",
    "    model_class=BaselineModel, model_name=BASELINE_MODEL,\n",
    "    use_weighted_ce=False, use_multitask=False, use_threshold_opt=False,\n",
    "    lr=2e-5, patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Incremental Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Config: config_A_weighted_ce_thresh_mt\n",
      "  Model: roberta-base\n",
      "  Weighted CE: True | Multi-task: True\n",
      "  Threshold Opt: True\n",
      "  Epochs: 20 | LR: 2e-05 | Patience: 5\n",
      "  Batch: 4 x 8 = 32 effective\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 1369.13it/s, Materializing param=encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CE class weights: [1.000, 9.548]\n",
      "    step 160/2094 (update 20) | avg loss so far: 1.0967\n",
      "    step 320/2094 (update 40) | avg loss so far: 1.0513\n",
      "    step 480/2094 (update 60) | avg loss so far: 1.0065\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.9552\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.9168\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.8837\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.8509\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.8099\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.7725\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.7476\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.7255\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.7061\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.6856\n",
      "  Epoch 1/20 — Loss: 0.6839 | F1: 0.4928 | P: 0.5822 | R: 0.4271\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.4319\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.4177\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.4050\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.4049\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.4109\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.3948\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.3972\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.4084\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.4118\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.4158\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.4143\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.4156\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.4078\n",
      "  Epoch 2/20 — Loss: 0.4074 | F1: 0.4883 | P: 0.3443 | R: 0.8392\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.2660\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.2559\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.2609\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.2615\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.2718\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.2809\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.2661\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.2843\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.3010\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.2960\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.2994\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.3065\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.3077\n",
      "  Epoch 3/20 — Loss: 0.3075 | F1: 0.5517 | P: 0.4626 | R: 0.6834\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.1708\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.1926\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.1926\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.1889\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.1828\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.1833\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.1847\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.1947\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.1926\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.1921\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.1887\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.1890\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.1902\n",
      "  Epoch 4/20 — Loss: 0.1899 | F1: 0.5835 | P: 0.5487 | R: 0.6231\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0984\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.1186\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.1285\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.1199\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.1108\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.1061\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.1037\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.1107\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.1103\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.1107\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.1218\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.1174\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.1265\n",
      "  Epoch 5/20 — Loss: 0.1262 | F1: 0.5559 | P: 0.6467 | R: 0.4874\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0855\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0594\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0673\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0655\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0754\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0733\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0774\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0856\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0804\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0872\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0875\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0835\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0923\n",
      "  Epoch 6/20 — Loss: 0.0918 | F1: 0.5659 | P: 0.6242 | R: 0.5176\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0180\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0474\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0415\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0367\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0387\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0385\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0355\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0378\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0401\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0377\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0354\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0404\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0409\n",
      "  Epoch 7/20 — Loss: 0.0407 | F1: 0.5920 | P: 0.6307 | R: 0.5578\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0677\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0562\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0566\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0509\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0529\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0460\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0439\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0427\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0402\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0410\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0409\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0419\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0396\n",
      "  Epoch 8/20 — Loss: 0.0394 | F1: 0.5910 | P: 0.6222 | R: 0.5628\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0117\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0307\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0304\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0258\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0225\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0254\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0267\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0316\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0289\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0279\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0320\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0305\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0320\n",
      "  Epoch 9/20 — Loss: 0.0319 | F1: 0.5777 | P: 0.5587 | R: 0.5980\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0447\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0277\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0261\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0294\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0251\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0220\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0203\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0193\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0186\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0212\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0207\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0197\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0188\n",
      "  Epoch 10/20 — Loss: 0.0188 | F1: 0.5721 | P: 0.5571 | R: 0.5879\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0072\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0168\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0264\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0229\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0195\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0177\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0190\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0177\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0197\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0184\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0182\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0179\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0170\n",
      "  Epoch 11/20 — Loss: 0.0170 | F1: 0.5860 | P: 0.5654 | R: 0.6080\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0092\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0076\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0068\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0071\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0068\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0066\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0065\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0064\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0067\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0068\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0070\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0083\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0088\n",
      "  Epoch 12/20 — Loss: 0.0088 | F1: 0.6042 | P: 0.6270 | R: 0.5829\n",
      "  -> New best F1! Saved.\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0067\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0063\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0059\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0060\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0056\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0078\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0076\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0074\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0100\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0096\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0091\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0094\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0091\n",
      "  Epoch 13/20 — Loss: 0.0099 | F1: 0.5816 | P: 0.5907 | R: 0.5729\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0042\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0044\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0059\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0055\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0052\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0049\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0048\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0049\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0047\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0046\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0049\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0048\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0048\n",
      "  Epoch 14/20 — Loss: 0.0048 | F1: 0.5650 | P: 0.6452 | R: 0.5025\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0037\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0052\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0073\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0065\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0059\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0056\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0110\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0158\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0144\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0134\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0124\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0116\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0110\n",
      "  Epoch 15/20 — Loss: 0.0109 | F1: 0.6041 | P: 0.6103 | R: 0.5980\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0031\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0029\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0029\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0028\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0029\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0028\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0029\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0028\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0028\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0028\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0050\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0049\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0048\n",
      "  Epoch 16/20 — Loss: 0.0048 | F1: 0.5833 | P: 0.6054 | R: 0.5628\n",
      "    step 160/2094 (update 20) | avg loss so far: 0.0025\n",
      "    step 320/2094 (update 40) | avg loss so far: 0.0024\n",
      "    step 480/2094 (update 60) | avg loss so far: 0.0025\n",
      "    step 640/2094 (update 80) | avg loss so far: 0.0026\n",
      "    step 800/2094 (update 100) | avg loss so far: 0.0027\n",
      "    step 960/2094 (update 120) | avg loss so far: 0.0027\n",
      "    step 1120/2094 (update 140) | avg loss so far: 0.0026\n",
      "    step 1280/2094 (update 160) | avg loss so far: 0.0026\n",
      "    step 1440/2094 (update 180) | avg loss so far: 0.0026\n",
      "    step 1600/2094 (update 200) | avg loss so far: 0.0026\n",
      "    step 1760/2094 (update 220) | avg loss so far: 0.0026\n",
      "    step 1920/2094 (update 240) | avg loss so far: 0.0038\n",
      "    step 2080/2094 (update 260) | avg loss so far: 0.0037\n",
      "  Epoch 17/20 — Loss: 0.0037 | F1: 0.5870 | P: 0.6075 | R: 0.5678\n",
      "  Early stopping at epoch 17\n",
      "\n",
      "  Dev F1 @ t=0.50: 0.6042\n",
      "  Dev F1 @ t=0.80 (optimised): 0.6138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      No PCL     0.9567    0.9668    0.9617      1895\n",
      "         PCL     0.6480    0.5829    0.6138       199\n",
      "\n",
      "    accuracy                         0.9303      2094\n",
      "   macro avg     0.8024    0.7748    0.7877      2094\n",
      "weighted avg     0.9273    0.9303    0.9286      2094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Config A: Weighted CE + Threshold Optimisation + Multi-task Learning\n",
    "metrics_a, thresh_metrics_a, history_a, thresh_a, tok_a = train_model(\n",
    "    config_name='config_A_weighted_ce_thresh_mt',\n",
    "    train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n",
    "    model_class=PCLMultiTaskModel, model_name='roberta-base',\n",
    "    use_weighted_ce=True, use_multitask=True, use_threshold_opt=True,\n",
    "    num_epochs=20, lr=2e-5, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Config: config_B_weighted_ce_thresh_mt\n",
      "  Model: roberta-large\n",
      "  Weighted CE: True | Multi-task: True\n",
      "  Threshold Opt: True\n",
      "  Epochs: 20 | LR: 1e-05 | Patience: 5\n",
      "  Batch: 4 x 8 = 32 effective\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 389/389 [00:00<00:00, 1427.25it/s, Materializing param=encoder.layer.23.output.dense.weight]              \n",
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: roberta-large\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CE class weights: [1.000, 9.548]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.57 GiB of which 18.31 MiB is free. Process 10515 has 3.20 GiB memory in use. Process 63824 has 6.04 GiB memory in use. Process 58338 has 390.00 MiB memory in use. Including non-PyTorch memory, this process has 5.05 GiB memory in use. Of the allocated memory 4.75 GiB is allocated by PyTorch, and 20.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m free_gpu()\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Config B: Weighted CE + Threshold Optimisation + Multi-task Learning\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m metrics_b, thresh_metrics_b, history_b, thresh_b, tok_b = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconfig_B_weighted_ce_thresh_mt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPCLMultiTaskModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mroberta-large\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_weighted_ce\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_multitask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threshold_opt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 146\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(config_name, train_df, dev_df, tokenizer, use_weighted_ce, use_threshold_opt, use_multitask, num_epochs, batch_size, grad_accum_steps, lr, weight_decay, patience, category_weight, model_class, model_name)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (step + \u001b[32m1\u001b[39m) % grad_accum_steps == \u001b[32m0\u001b[39m:\n\u001b[32m    145\u001b[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     scheduler.step()\n\u001b[32m    148\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:166\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m opt = opt_ref()\n\u001b[32m    165\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:526\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    521\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    522\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    523\u001b[39m             )\n\u001b[32m    525\u001b[39m \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/optim/adam.py:238\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     state_steps: \u001b[38;5;28mlist\u001b[39m[Tensor] = []\n\u001b[32m    236\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     has_complex = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m     adam(\n\u001b[32m    249\u001b[39m         params_with_grad,\n\u001b[32m    250\u001b[39m         grads,\n\u001b[32m   (...)\u001b[39m\u001b[32m    269\u001b[39m         decoupled_weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    270\u001b[39m     )\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/optim/adam.py:178\u001b[39m, in \u001b[36mAdam._init_group\u001b[39m\u001b[34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[39m\n\u001b[32m    168\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m    169\u001b[39m     torch.zeros(\n\u001b[32m    170\u001b[39m         (),\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m torch.tensor(\u001b[32m0.0\u001b[39m, dtype=_get_scalar_dtype())\n\u001b[32m    176\u001b[39m )\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mexp_avg\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreserve_format\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[32m    182\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mexp_avg_sq\u001b[39m\u001b[33m\"\u001b[39m] = torch.zeros_like(\n\u001b[32m    183\u001b[39m     p, memory_format=torch.preserve_format\n\u001b[32m    184\u001b[39m )\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.57 GiB of which 18.31 MiB is free. Process 10515 has 3.20 GiB memory in use. Process 63824 has 6.04 GiB memory in use. Process 58338 has 390.00 MiB memory in use. Including non-PyTorch memory, this process has 5.05 GiB memory in use. Of the allocated memory 4.75 GiB is allocated by PyTorch, and 20.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "free_gpu()\n",
    "# Config B: Weighted CE + Threshold Optimisation + Multi-task Learning\n",
    "metrics_b, thresh_metrics_b, history_b, thresh_b, tok_b = train_model(\n",
    "    config_name='config_B_weighted_ce_thresh_mt',\n",
    "    train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n",
    "    model_class=PCLMultiTaskModel, model_name='roberta-large',\n",
    "    use_weighted_ce=True, use_multitask=True, use_threshold_opt=True,\n",
    "    num_epochs=20, lr=1e-5, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ablation Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Config: ablation_no_multitask\n",
      "  Model: roberta-base\n",
      "  Weighted CE: True | Multi-task: False\n",
      "  Threshold Opt: True\n",
      "  Epochs: 10 | LR: 2e-05 | Patience: 5\n",
      "  Batch: 4 x 8 = 32 effective\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 1422.82it/s, Materializing param=encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 15.57 GiB of which 7.81 MiB is free. Process 10515 has 3.20 GiB memory in use. Process 63824 has 6.04 GiB memory in use. Process 58338 has 390.00 MiB memory in use. Including non-PyTorch memory, this process has 5.35 GiB memory in use. Of the allocated memory 5.05 GiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ablation 1: Config A without multi-task (isolate multi-task contribution)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m metrics_abl_nomt, thresh_metrics_abl_nomt, history_abl_nomt, thresh_abl_nomt, tok_abl_nomt = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mablation_no_multitask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdev_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBaselineModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mroberta-base\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_weighted_ce\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_multitask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threshold_opt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Ablation 2: Config A without threshold opt (isolate threshold contribution)\u001b[39;00m\n\u001b[32m     11\u001b[39m metrics_abl_nothresh, thresh_metrics_abl_nothresh, history_abl_nothresh, thresh_abl_nothresh, tok_abl_nothresh = train_model(\n\u001b[32m     12\u001b[39m     config_name=\u001b[33m'\u001b[39m\u001b[33mablation_no_thresh\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     13\u001b[39m     train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     lr=\u001b[32m2e-5\u001b[39m, patience=\u001b[32m5\u001b[39m\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(config_name, train_df, dev_df, tokenizer, use_weighted_ce, use_threshold_opt, use_multitask, num_epochs, batch_size, grad_accum_steps, lr, weight_decay, patience, category_weight, model_class, model_name)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_class == BaselineModel:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     model = \u001b[43mBaselineModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m.float()\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     95\u001b[39m     model = PCLMultiTaskModel(model_name=model_name).to(DEVICE).float()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1381\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1379\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:933\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:933\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:933\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:964\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    961\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    965\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    967\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/akc123/PCL_Detection/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1367\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1361\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1362\u001b[39m             device,\n\u001b[32m   1363\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1364\u001b[39m             non_blocking,\n\u001b[32m   1365\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1366\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 15.57 GiB of which 7.81 MiB is free. Process 10515 has 3.20 GiB memory in use. Process 63824 has 6.04 GiB memory in use. Process 58338 has 390.00 MiB memory in use. Including non-PyTorch memory, this process has 5.35 GiB memory in use. Of the allocated memory 5.05 GiB is allocated by PyTorch, and 15.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Ablation 1: Config A without multi-task (isolate multi-task contribution)\n",
    "metrics_abl_nomt, thresh_metrics_abl_nomt, history_abl_nomt, thresh_abl_nomt, tok_abl_nomt = train_model(\n",
    "    config_name='ablation_no_multitask',\n",
    "    train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n",
    "    model_class=BaselineModel, model_name='roberta-base',\n",
    "    use_weighted_ce=True, use_multitask=False, use_threshold_opt=True,\n",
    "    lr=2e-5, patience=5\n",
    ")\n",
    "\n",
    "# Ablation 2: Config A without threshold opt (isolate threshold contribution)\n",
    "metrics_abl_nothresh, thresh_metrics_abl_nothresh, history_abl_nothresh, thresh_abl_nothresh, tok_abl_nothresh = train_model(\n",
    "    config_name='ablation_no_thresh',\n",
    "    train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n",
    "    model_class=PCLMultiTaskModel, model_name='roberta-base',\n",
    "    use_weighted_ce=True, use_multitask=True, use_threshold_opt=False,\n",
    "    lr=2e-5, patience=5\n",
    ")\n",
    "\n",
    "# Ablation 3: Config A without weighted CE (isolate weighted CE contribution)\n",
    "metrics_abl_nowe, thresh_metrics_abl_nowe, history_abl_nowe, thresh_abl_nowe, tok_abl_nowe = train_model(\n",
    "    config_name='ablation_no_weighted_ce',\n",
    "    train_df=train_df, dev_df=dev_df, tokenizer=tokenizer,\n",
    "    model_class=PCLMultiTaskModel, model_name='roberta-base',\n",
    "    use_weighted_ce=False, use_multitask=True, use_threshold_opt=True,\n",
    "    lr=2e-5, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Comparison & Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Results comparison table ----\n",
    "results = pd.DataFrame([\n",
    "    {\n",
    "        'Config': 'Baseline (unweighted CE, t=0.5)',\n",
    "        'Threshold': '0.50',\n",
    "        'F1': thresh_metrics_bl['f1'],\n",
    "        'Precision': thresh_metrics_bl['precision'],\n",
    "        'Recall': thresh_metrics_bl['recall'],\n",
    "    },\n",
    "    {\n",
    "        'Config': 'A: + Weighted CE + Thresh Opt + Multi-task',\n",
    "        'Threshold': f'{thresh_a:.2f}',\n",
    "        'F1': thresh_metrics_a['f1'],\n",
    "        'Precision': thresh_metrics_a['precision'],\n",
    "        'Recall': thresh_metrics_a['recall'],\n",
    "    },\n",
    "    {\n",
    "        'Config': 'Ablation: A w/o Multi-task',\n",
    "        'Threshold': f'{thresh_abl_nomt:.2f}',\n",
    "        'F1': thresh_metrics_abl_nomt['f1'],\n",
    "        'Precision': thresh_metrics_abl_nomt['precision'],\n",
    "        'Recall': thresh_metrics_abl_nomt['recall'],\n",
    "    },\n",
    "    {\n",
    "        'Config': 'Ablation: A w/o Threshold Opt',\n",
    "        'Threshold': '0.50',\n",
    "        'F1': thresh_metrics_abl_nothresh['f1'],\n",
    "        'Precision': thresh_metrics_abl_nothresh['precision'],\n",
    "        'Recall': thresh_metrics_abl_nothresh['recall'],\n",
    "    },\n",
    "    {\n",
    "        'Config': 'Ablation: A w/o Weighted CE',\n",
    "        'Threshold': f'{thresh_abl_nowe:.2f}',\n",
    "        'F1': thresh_metrics_abl_nowe['f1'],\n",
    "        'Precision': thresh_metrics_abl_nowe['precision'],\n",
    "        'Recall': thresh_metrics_abl_nowe['recall'],\n",
    "    },\n",
    "])\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('RESULTS COMPARISON (all models evaluated on dev set)')\n",
    "print('='*80)\n",
    "print(results.to_string(index=False, float_format='{:.4f}'.format))\n",
    "\n",
    "# Best model is Config A\n",
    "best_metrics = thresh_metrics_a\n",
    "best_threshold = thresh_a\n",
    "best_tok = tok_a\n",
    "best_ckpt_name = 'config_A_weighted_ce_thresh_mt'\n",
    "best_model_class = PCLMultiTaskModel\n",
    "best_model_name = 'roberta-base'\n",
    "best_key = 'A'\n",
    "\n",
    "improvement = best_metrics['f1'] - thresh_metrics_bl['f1']\n",
    "print(f'\\n** Best model: Config A (F1={best_metrics[\"f1\"]:.4f} @ t={best_threshold:.2f}) **')\n",
    "print(f'   Improvement over baseline: +{improvement:.4f} F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate dev.txt and test.txt Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Dev predictions ----\n",
    "dev_preds = best_metrics['preds']\n",
    "dev_pred_path = f'{BASE_DIR}/dev.txt'\n",
    "with open(dev_pred_path, 'w') as f:\n",
    "    for p in dev_preds:\n",
    "        f.write(f'{p}\\n')\n",
    "print(f'Dev predictions saved to {dev_pred_path}')\n",
    "print(f'  {len(dev_preds)} predictions, {sum(dev_preds)} predicted PCL')\n",
    "\n",
    "# ---- Test predictions ----\n",
    "test_df = pd.read_csv(f'{DATA_DIR}/task4_test.tsv', sep='\\t', header=None,\n",
    "                       names=['par_id', 'art_id', 'keyword', 'country_code', 'text'])\n",
    "test_df['text'] = test_df['text'].apply(clean_text)\n",
    "print(f'\\nTest set: {len(test_df)} samples')\n",
    "\n",
    "test_dataset = PCLDataset(\n",
    "    texts=test_df['text'].tolist(),\n",
    "    binary_labels=[0] * len(test_df),\n",
    "    category_labels=[[0]*7] * len(test_df),\n",
    "    tokenizer=best_tok, max_length=MAX_LENGTH\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Reload best model from checkpoint\n",
    "best_model = PCLMultiTaskModel(model_name=best_model_name).to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/{best_ckpt_name}_best.pt', weights_only=True, map_location=DEVICE))\n",
    "best_model.eval()\n",
    "\n",
    "test_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        binary_logits, _ = best_model(input_ids, attention_mask)\n",
    "        probs = F.softmax(binary_logits, dim=1)[:, 1].cpu().tolist()\n",
    "        test_probs.extend(probs)\n",
    "\n",
    "del best_model; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "test_preds = [1 if p >= best_threshold else 0 for p in test_probs]\n",
    "\n",
    "test_pred_path = f'{BASE_DIR}/test.txt'\n",
    "with open(test_pred_path, 'w') as f:\n",
    "    for p in test_preds:\n",
    "        f.write(f'{p}\\n')\n",
    "print(f'Test predictions saved to {test_pred_path}')\n",
    "print(f'  {len(test_preds)} predictions, {sum(test_preds)} predicted PCL')\n",
    "print(f'  Using threshold: {best_threshold:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Error analysis: compare baseline vs best model ----\n",
    "# Reload baseline from checkpoint\n",
    "model_baseline = BaselineModel(model_name=BASELINE_MODEL).to(DEVICE)\n",
    "model_baseline.load_state_dict(torch.load(f'{CHECKPOINT_DIR}/baseline_best.pt', weights_only=True, map_location=DEVICE))\n",
    "\n",
    "baseline_dev_metrics = evaluate(model_baseline,\n",
    "    DataLoader(PCLDataset(dev_df['text'].tolist(), dev_df['binary_label'].tolist(),\n",
    "                          dev_df['category_labels'].tolist(), tok_bl, MAX_LENGTH),\n",
    "               batch_size=EVAL_BATCH_SIZE, shuffle=False),\n",
    "    DEVICE, threshold=0.5)\n",
    "\n",
    "del model_baseline; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "baseline_preds = baseline_dev_metrics['preds']\n",
    "best_preds = best_metrics['preds']\n",
    "true_labels = best_metrics['labels']\n",
    "dev_texts = dev_df['text'].tolist()\n",
    "\n",
    "print('='*60)\n",
    "print('ERROR ANALYSIS: Baseline vs Best Model on Dev Set')\n",
    "print('='*60)\n",
    "\n",
    "baseline_fp = sum(1 for t, p in zip(true_labels, baseline_preds) if t == 0 and p == 1)\n",
    "baseline_fn = sum(1 for t, p in zip(true_labels, baseline_preds) if t == 1 and p == 0)\n",
    "baseline_tp = sum(1 for t, p in zip(true_labels, baseline_preds) if t == 1 and p == 1)\n",
    "best_fp = sum(1 for t, p in zip(true_labels, best_preds) if t == 0 and p == 1)\n",
    "best_fn = sum(1 for t, p in zip(true_labels, best_preds) if t == 1 and p == 0)\n",
    "best_tp = sum(1 for t, p in zip(true_labels, best_preds) if t == 1 and p == 1)\n",
    "\n",
    "print(f'\\n{\"Metric\":<25} {\"Baseline\":>10} {\"Best Model\":>12}')\n",
    "print('-' * 50)\n",
    "print(f'{\"True Positives\":<25} {baseline_tp:>10} {best_tp:>12}')\n",
    "print(f'{\"False Positives\":<25} {baseline_fp:>10} {best_fp:>12}')\n",
    "print(f'{\"False Negatives\":<25} {baseline_fn:>10} {best_fn:>12}')\n",
    "\n",
    "fixed_fn = []\n",
    "fixed_fp = []\n",
    "for i, (t, bp, mp) in enumerate(zip(true_labels, baseline_preds, best_preds)):\n",
    "    if t == 1 and bp == 0 and mp == 1:\n",
    "        fixed_fn.append(i)\n",
    "    if t == 0 and bp == 1 and mp == 0:\n",
    "        fixed_fp.append(i)\n",
    "\n",
    "print(f'\\nBest model fixes {len(fixed_fn)} FN and {len(fixed_fp)} FP from baseline')\n",
    "\n",
    "print(f'\\n--- PCL missed by baseline but caught by best model ({min(5, len(fixed_fn))} shown) ---')\n",
    "for idx in fixed_fn[:5]:\n",
    "    print(f'  [{idx}] {dev_texts[idx][:150]}...')\n",
    "\n",
    "remaining_fn = [i for i, (t, p) in enumerate(zip(true_labels, best_preds)) if t == 1 and p == 0]\n",
    "print(f'\\n--- Remaining false negatives ({min(5, len(remaining_fn))}/{len(remaining_fn)} shown) ---')\n",
    "for idx in remaining_fn[:5]:\n",
    "    print(f'  [{idx}] {dev_texts[idx][:150]}...')\n",
    "\n",
    "fn_lengths = [len(dev_texts[i].split()) for i in remaining_fn]\n",
    "fp_indices = [i for i, (t, p) in enumerate(zip(true_labels, best_preds)) if t == 0 and p == 1]\n",
    "fp_lengths = [len(dev_texts[i].split()) for i in fp_indices]\n",
    "all_lengths = [len(t.split()) for t in dev_texts]\n",
    "\n",
    "print(f'\\n--- Text length analysis ---')\n",
    "print(f'  Overall mean length:     {np.mean(all_lengths):.1f} words')\n",
    "print(f'  False negative mean:     {np.mean(fn_lengths):.1f} words' if fn_lengths else '  No false negatives')\n",
    "print(f'  False positive mean:     {np.mean(fp_lengths):.1f} words' if fp_lengths else '  No false positives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Precision-Recall Curve: Best Model vs Baseline ----\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Left: Precision-Recall Curves ---\n",
    "ax = axes[0]\n",
    "\n",
    "# Best model PR curve\n",
    "prec_best, rec_best, thresholds_best = precision_recall_curve(\n",
    "    best_metrics['labels'], best_metrics['probs'], pos_label=1)\n",
    "ax.plot(rec_best, prec_best, label=f'Best model ({best_key})', color='tab:blue', linewidth=2)\n",
    "\n",
    "# Baseline PR curve\n",
    "prec_base, rec_base, thresholds_base = precision_recall_curve(\n",
    "    baseline_dev_metrics['labels'], baseline_dev_metrics['probs'], pos_label=1)\n",
    "ax.plot(rec_base, prec_base, label='RoBERTa-base baseline', color='tab:orange', linewidth=2, linestyle='--')\n",
    "\n",
    "# Mark the operating points\n",
    "ax.scatter([best_metrics['recall']], [best_metrics['precision']],\n",
    "           marker='*', s=200, color='tab:blue', zorder=5, label=f'Best @ t={best_threshold:.2f}')\n",
    "ax.scatter([baseline_dev_metrics['recall']], [baseline_dev_metrics['precision']],\n",
    "           marker='*', s=200, color='tab:orange', zorder=5, label=f'Baseline @ t={thresh_bl:.2f}')\n",
    "\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=13)\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_xlim([0, 1.02])\n",
    "ax.set_ylim([0, 1.02])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Right: Confusion Matrix Heatmap (Best Model) ---\n",
    "ax = axes[1]\n",
    "\n",
    "cm = confusion_matrix(best_metrics['labels'], best_metrics['preds'], labels=[0, 1])\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "classes = ['No PCL (0)', 'PCL (1)']\n",
    "tick_marks = [0, 1]\n",
    "ax.set_xticks(tick_marks)\n",
    "ax.set_xticklabels(classes, fontsize=11)\n",
    "ax.set_yticks(tick_marks)\n",
    "ax.set_yticklabels(classes, fontsize=11)\n",
    "\n",
    "# Annotate each cell with count\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "        ax.text(j, i, f'{cm[i, j]}', ha='center', va='center', fontsize=16, fontweight='bold', color=color)\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title(f'Confusion Matrix — Best Model ({best_key}, t={best_threshold:.2f})', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{BASE_DIR}/custom_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'Figure saved to {BASE_DIR}/custom_metrics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Ablation Study Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Ablation Study Summary ----\n",
    "ablation_table = pd.DataFrame([\n",
    "    {'Config': 'Baseline (unweighted CE, t=0.5)', 'Weighted CE': 'No', 'Multi-task': 'No', 'Thresh Opt': 'No',\n",
    "     'Dev F1': f'{thresh_metrics_bl[\"f1\"]:.4f}'},\n",
    "    {'Config': 'Config A (full)', 'Weighted CE': 'Yes', 'Multi-task': 'Yes', 'Thresh Opt': 'Yes',\n",
    "     'Dev F1': f'{thresh_metrics_a[\"f1\"]:.4f}'},\n",
    "    {'Config': 'A w/o Multi-task', 'Weighted CE': 'Yes', 'Multi-task': 'No', 'Thresh Opt': 'Yes',\n",
    "     'Dev F1': f'{thresh_metrics_abl_nomt[\"f1\"]:.4f}'},\n",
    "    {'Config': 'A w/o Threshold Opt', 'Weighted CE': 'Yes', 'Multi-task': 'Yes', 'Thresh Opt': 'No',\n",
    "     'Dev F1': f'{thresh_metrics_abl_nothresh[\"f1\"]:.4f}'},\n",
    "    {'Config': 'A w/o Weighted CE', 'Weighted CE': 'No', 'Multi-task': 'Yes', 'Thresh Opt': 'Yes',\n",
    "     'Dev F1': f'{thresh_metrics_abl_nowe[\"f1\"]:.4f}'},\n",
    "])\n",
    "\n",
    "print('='*80)\n",
    "print('ABLATION STUDY')\n",
    "print('='*80)\n",
    "print(ablation_table.to_string(index=False))\n",
    "\n",
    "# Component contributions\n",
    "full_f1 = thresh_metrics_a['f1']\n",
    "print(f'\\nComponent contributions (F1 drop when removed from Config A):')\n",
    "print(f'  Multi-task learning:    {full_f1 - thresh_metrics_abl_nomt[\"f1\"]:+.4f}')\n",
    "print(f'  Threshold optimisation: {full_f1 - thresh_metrics_abl_nothresh[\"f1\"]:+.4f}')\n",
    "print(f'  Weighted CE:            {full_f1 - thresh_metrics_abl_nowe[\"f1\"]:+.4f}')\n",
    "print(f'\\nTotal improvement over baseline: {full_f1 - thresh_metrics_bl[\"f1\"]:+.4f} F1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
